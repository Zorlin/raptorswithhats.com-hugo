Today I received my first ODROID-HC2 node, and immediately went out and bought everything I needed... kind of.

Shopping list:
- SDcard, at least 16GB, preferably fast ($25)
- WD RED 4TB drive, new ($180)
- Network cable
- Wireless adapter for The Cube (loungeroom PC) ($69)

The cluster will be called geckobox, as it's destined to run LizardFS.

The names of each of the nodes...
- blinky
- pinky
- inky
- clyde

This first node is called Blinky and was the most expensive - bought it through JiffyShop for about $155 including PSU and case and the unit itself.

First stumbling block... I don't have any screwdrivers as I just moved. Drat. Need to buy a set tomorrow.

Let's get started... plugged the SD card into my MacBook and went looking for images...

Looks like we can grab the latest release (at the time of this blog) here: https://wiki.odroid.com/odroid-xu4/os_images/linux/ubuntu_4.14/ubuntu_4.14
Let's pull it down with axel...

rain:images wings$ axel -a https://odroid.in/ubuntu_18.04lts/ubuntu-18.04-4.14-minimal-odroid-xu4-20180531.img.xz

Gotta take advantage of that FTTB ;) 1 minute later and I have the image.

Next stumbling block - it's an xz archive which isn't the most user-friendly. Looks like I already have unxz installed somehow, so that's good?

rain:images wings$ unxz ubuntu-18.04-4.14-minimal-odroid-xu4-20180531.img.xz

All up it's a 2GB image. Ouch... I really need to wipe my Mac and get back some space as I only have 9GB left after that.

HardKernel (the manufacturer of ODROID boards) recommends you use Etcher to burn the image to the SDcard. I'm inclined to agree as while I could do
clever stuff like writing it with dd I don't really want to bother. A nice GUI sounds good to me, especially one that's open source...

Alrighty, fired it up and... it didn't work. Power cycled it and it appears to boot - as 10.1.1.66! Hooray!

I'm going to put the ODROIDs in the 10.1.1.200 range. The master IP will be 10.1.1.200, then the nodes will live at 201, 202, 203 etc. 
I'm going to use DHCP Static Leases for more flexibility.

Logged in as odroid:odroid... which didn't work. But root:odroid worked just fine. Interesting.

First things first, let's set a better rootpw:

root@odroid:~# passwd
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully

Done.

apt update and upgrade.

Change hostname to blinky
nano /etc/hostname

Reboot to make the new kernel and hostname take effect.

At this stage there's a major TODO - I want to create a regular user account with sudo privileges and avoid logging in as root. 
Just a personal preference. But let's get the other major stuff out of the way first.

Let's look at Known Issues - https://wiki.odroid.com/odroid-xu4/troubleshooting/known_issue

As we're using a HC2 we need to add this tweaked shutdown script, as described here: https://wiki.odroid.com/odroid-xu4/troubleshooting/shutdown_script

Set up the static lease and reboot.

Okay, time to prepare the star of the show - our 4TB drive. Some grepping around in /dev indicates it lives at /dev/sda which makes things
quite simple. We're not going to bother partitioning it, and will instead simply lay down an ext4 filesystem straight onto the disk.
Once that's done, we will add it as a brick in LizardFS.

(Sidenote: I want to explore other brick types such as ZFS, XFS etc. ZFS needs too much RAM, XFS needs too much tuning, ext4 will "just work" for now.
Once I'm a bit more established and can justify risking data, I'll try XFS again...)

Lay down the FS:

root@blinky:~# mkfs.ext4 /dev/sda
mke2fs 1.44.1 (24-Mar-2018)
Creating filesystem with 976754646 4k blocks and 244195328 inodes
Filesystem UUID: 269c0544-8af0-4091-91b9-7ded7eb25868
Superblock backups stored on blocks:
    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
    4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,
    102400000, 214990848, 512000000, 550731776, 644972544

Allocating group tables: done
Writing inode tables: done
Creating journal (262144 blocks): done
Writing superblocks and filesystem accounting information: done

Make our brick directory
root@blinky:~# mkdir /lfsbrick

Mount our brick as /lfsbrick/
root@blinky:~# mount /dev/sda /lfsbrick/

In multiple-disk systems I would probably say stuff like /lfsbrick.01 instead, but these
ODROIDs are intended to only have a single disk.

Let's check out our newly mounted brick -

root@blinky:~# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda        3.6T   89M  3.4T   1% /lfsbrick

Excellent, that seemed to work great. Next steps will be actually installing LizardFS,
then some minor housekeeping (automount our brick in /etc/fstab, for one thing) and
we'll be golden.

Against my better judgment I'm going to use the official LizardFS repo. On a cluster where stability is everything I would likely use the native Ubuntu/Debian packages instead of the vendor packages (LizardFS' official ones).

https://docs.lizardfs.com/adminguide/installation.html#get-and-install-debian

...Okay, looks like I have to use the Ubuntu packages anyways as the official ones don't work for me.
https://github.com/lizardfs/lizardfs/issues/751

- Install lizardfs-master
- Install lizardfs-common

Copy configs into place
root@blinky:/etc/lizardfs# cp /usr/share/doc/lizardfs-master/examples/*.cfg .

In mfsmaster.cfg
Set PERSONALITY = master on Blinky
Set ADMIN_PASSWORD = REDACTED on Blinky
Set MASTER_HOST = 10.1.1.201 (to be changed to 200 when uraft released)

Save it

Enable the master service
root@blinky:/etc/lizardfs# sudo systemctl enable lizardfs-master

As this is a new installation, trying to start the master results in an error:
Aug 31 11:30:39 blinky mfsmaster[3114]: can't open metadata file /var/lib/lizardfs/metadata.mfs: if this is a new installation create empty metadata by copying /var/lib/lizardfs/metadata by copying /var/lib/lizardfs/metadata.mfs.empty to /var/lib/lizardfs/metadata.mfs

This is a very important safety in LFS to avoid purging metadata. Follow the instructions...
root@blinky:/var/lib/lizardfs# cp metadata.mfs.empty metadata.mfs

Now it should start 
root@blinky:/var/lib/lizardfs# systemctl start lizardfs-master

At this point it might be worth fixing autocomplete which hasn't been working this whole time!

sudo apt install bash-completion

And then we install the cgi services.
root@blinky:~# apt-get install lizardfs-cgi lizardfs-cgiserv

Enable and run the cgiserv
root@blinky:~# systemctl enable lizardfs-cgiserv.service
root@blinky:~# systemctl start lizardfs-cgiserv

Now check it out - we have a functioning installation!
http://10.1.1.201:9425/mfs.cgi

Unfortunately no place to store data yet ;)

Let's install our first chunkserver!

root@blinky:~# apt install lizardfs-chunkserver

Copy configs into place
root@blinky:/etc/lizardfs# cp /usr/share/doc/lizardfs-chunkserver/examples/* .
root@blinky:/etc/lizardfs# gunzip mfschunkserver.cfg.gz

Edit /etc/lizardfs/mfshdd.cfg
Add our brick - /lfsbrick/geckobox
Note that our brick exists as a folder in the /lfsbrick/ filesystem, not directly
on the mount. That's to avoid a situation where the chunkserver starts while the
drive isn't yet mounted.

Edit /etc/lizardfs/mfschunkserver.cfg
Set MASTER_HOST = 10.1.1.201

Chown our brick directory
root@blinky:/lfsbrick# chown -R lizardfs:lizardfs /lfsbrick/geckobox/

Enable and run the chunkserver
root@blinky:~# systemctl enable lizardfs-chunkserver.service
root@blinky:~# systemctl start lizardfs-chunkserver

We should now have our first chunkserver in service and around ~3.4TiB free, which we indeed have!

Grab the client:
root@blinky:/lfsbrick# apt install lizardfs-client

Copy configs into place
root@blinky:/etc/lizardfs# cp /usr/share/doc/lizardfs-client/examples/mfsmount.cfg .

We're going to mount to /mnt/lfs/ til I can find a better idea.

Before we configure the lizardfs-client, we'll add some password protection. This doesn't add encryption but
makes your installation a bit harder to snoop on and tamper with.

root@blinky:~# nano /etc/lizardfs/mfsexports.cfg

Change this:
============
# mfsexports.cfg(5)
# Allow everything but "meta".
*                       /       rw,alldirs,maproot=0,ignoregid

# Allow "meta".
*                       .       rw
===========

To this:
===========
# mfsexports.cfg(5)
# Allow everything but "meta".
*                       /       rw,alldirs,maproot=0,ignoregid,password=examplemainpass

# Allow "meta".
*                       .       rw,password=examplemetapass

Now we want to edit /etc/lizardfs/mfsmount.cfg -

/mnt/lfs
mfsmaster=10.1.1.201
mfspassword=examplemainpass

Awesome!

We can now try to mount LizardFS!

root@blinky:~# mfsmount
mfsmaster accepted connection with parameters: read-write,restricted_ip,ignore_gid ; root mapped to root:root

We'll add entries in /etc/fstab later at the same time we add the bricks. For now this install
is just a basic proof of concept.

Before we begin setting up services etc, we need to do some minor tuning.
We have a massive 4TB drive, and the defaults for ext4 reserve a TON of space. Check it out!

Filesystem           Size  Used Avail Use% Mounted on
/dev/sda             3.6T   90M  3.4T   1% /lfsbrick

Note the difference between Size and Avail - about 200GB.

We want to reserve a little space just in case, but 5% is ridiculous. Let's do 0.5%.

root@blinky:~# sudo tune2fs -m 0.5 /dev/sda
tune2fs 1.44.1 (24-Mar-2018)
Setting reserved blocks percentage to 0.5% (4883773 blocks)

Now let's check it out again...
Filesystem           Size  Used Avail Use% Mounted on
/dev/sda             3.6T   90M  3.6T   1% /lfsbrick

Much better! Further tuning is probably needed at some point but that gave a big boost to our free space.

LizardFS is installed and mounted now, so go play and create whatever structure you want.

Time to setup users.

root@blinky:~# adduser wings
root@blinky:~# usermod -aG sudo wings

Install netatalk so the MacBook can talk to us via AFP
root@blinky:~# apt install netatalk

We'll continue tomorrow...
